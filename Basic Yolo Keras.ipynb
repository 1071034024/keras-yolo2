{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Introduction**\n",
    "\n",
    "This is a proof of concept implementation of YOLOv2 using Keras.\n",
    "\n",
    "https://github.com/experiencor/basic-yolo-keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Outline of Steps**\n",
    "    + Initialization of parameters\n",
    "        + Download VOC data from http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar\n",
    "        + Download pre-trained weights from http://pjreddie.com/media/files/tiny-yolo-voc.weights\n",
    "        + Specify the directory of annotations by setting variable *ann_di*\n",
    "        + Specify the directory of images by setting variable *img_dir*\n",
    "        + Specity the path of pre-trained weights by setting variable *wt_path*\n",
    "    + Construct equivalent network in Keras\n",
    "        + Network arch from https://github.com/pjreddie/darknet/blob/master/cfg/tiny-yolo-voc.cfg\n",
    "    + Load the pretrained weights\n",
    "    + Preprocess VOC data\n",
    "    + Perform training (for POC, the weights of the last layers are randomized before training)\n",
    "    + Perform detection on an image with newly trained weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Initialization of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-22T07:04:39.558767Z",
     "start_time": "2017-03-22T15:04:38.649442+08:00"
    },
    "code_folding": [],
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Reshape, Activation, Convolution2D, Conv2D, Input, ZeroPadding2D, MaxPooling2D, BatchNormalization, Flatten, Dense\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-22T07:04:39.563469Z",
     "start_time": "2017-03-22T15:04:39.560403+08:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "wt_path = 'tiny-yolo-voc.weights'\n",
    "ann_dir = '/home/husky/data/pascal/VOCdevkit/VOC2012/Annotations/'\n",
    "img_dir = '/home/husky/data/pascal/VOCdevkit/VOC2012/JPEGImages/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-22T07:04:40.092560Z",
     "start_time": "2017-03-22T15:04:39.564747+08:00"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/cpu:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 9094628461267502432\n",
      ", name: \"/gpu:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 4591910912\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 2671535487995463974\n",
      "physical_device_desc: \"device: 0, name: Tesla K20c, pci bus id: 0000:3c:00.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "execfile('utils.py')\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "%matplotlib inline\n",
    "\n",
    "LABELS = ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']\n",
    "NORM_H, NORM_W = 416, 416\n",
    "GRID_H, GRID_W = 13 , 13\n",
    "BATCH_SIZE = 8\n",
    "BOX = 5\n",
    "CLASS = 20\n",
    "THRESHOLD = 0.2\n",
    "ANCHORS = '1.08,1.19,  3.42,4.41,  6.63,11.38,  9.42,5.11,  16.62,10.52'\n",
    "ANCHORS = [float(ANCHORS.strip()) for ANCHORS in ANCHORS.split(',')]\n",
    "SCALE_NOOB, SCALE_CONF, SCALE_COOR, SCALE_PROB = 1.0, 5.0, 1.0, 1.0\n",
    "weight_reader = WeightReader(wt_path)\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "heading_collapsed": true
   },
   "source": [
    "## Construct the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-22T07:04:40.532412Z",
     "start_time": "2017-03-22T15:04:40.095497+08:00"
    },
    "code_folding": [],
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Layer 1\n",
    "model.add(ZeroPadding2D(padding=(1,1), input_shape=(416,416,3)))\n",
    "model.add(Convolution2D(16, 3, 3, subsample=(1,1), bias=False))\n",
    "model.add(BatchNormalization(mode=0))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 2 - 5\n",
    "for i in range(0,4):\n",
    "    model.add(ZeroPadding2D(padding=(1,1)))\n",
    "    model.add(Convolution2D(32*(2**i), 3, 3, subsample=(1,1), bias=False))\n",
    "    model.add(BatchNormalization(mode=0))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 6\n",
    "model.add(ZeroPadding2D(padding=(1,1)))\n",
    "model.add(Convolution2D(512, 3, 3, subsample=(1,1), bias=False))\n",
    "model.add(BatchNormalization(mode=0))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(1,1), border_mode='same'))\n",
    "\n",
    "# Layer 7 - 8\n",
    "for _ in range(0,2):\n",
    "    model.add(ZeroPadding2D(padding=(1,1)))\n",
    "    model.add(Convolution2D(1024, 3, 3, subsample=(1,1), bias=False))\n",
    "    model.add(BatchNormalization(mode=0))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "# Layer 9\n",
    "model.add(Convolution2D(125, 1, 1, subsample=(1,1)))\n",
    "model.add(Activation('linear'))\n",
    "model.add(Reshape((13, 13, 5, 25)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "heading_collapsed": true
   },
   "source": [
    "## Load pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-22T07:04:42.200442Z",
     "start_time": "2017-03-22T15:04:40.534153+08:00"
    },
    "code_folding": [],
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "weight_reader.reset()\n",
    "\n",
    "for i in range(len(model.layers)):\n",
    "    if 'conv' in model.layers[i].name:\n",
    "        if 'batch' in model.layers[i+1].name:\n",
    "            norm_layer = model.layers[i+1]\n",
    "            size = np.prod(norm_layer.get_weights()[0].shape)\n",
    "            \n",
    "            beta  = weight_reader.read_bytes(size)\n",
    "            gamma = weight_reader.read_bytes(size)\n",
    "            mean  = weight_reader.read_bytes(size)\n",
    "            var   = weight_reader.read_bytes(size)\n",
    "            \n",
    "            weights = norm_layer.set_weights([gamma, beta, mean, var])\n",
    "            \n",
    "        conv_layer = model.layers[i]\n",
    "        if len(conv_layer.get_weights()) > 1:\n",
    "            bias   = weight_reader.read_bytes(np.prod(conv_layer.get_weights()[1].shape))\n",
    "            kernel = weight_reader.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
    "            kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
    "            kernel = kernel.transpose([2,3,1,0])\n",
    "            conv_layer.set_weights([kernel, bias])\n",
    "        else:\n",
    "            kernel = weight_reader.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
    "            kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
    "            kernel = kernel.transpose([2,3,1,0])\n",
    "            conv_layer.set_weights([kernel])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "heading_collapsed": true
   },
   "source": [
    "## Preprocess VOC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-22T07:04:51.469253Z",
     "start_time": "2017-03-22T15:04:42.203884+08:00"
    },
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_img = parse_annotation(ann_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Perform training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Loss function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-02-01T20:44:50.211553",
     "start_time": "2017-02-01T20:44:50.206006"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "$$\\begin{multline}\n",
    "\\lambda_\\textbf{coord}\n",
    "\\sum_{i = 0}^{S^2}\n",
    "    \\sum_{j = 0}^{B}\n",
    "     L_{ij}^{\\text{obj}}\n",
    "            \\left[\n",
    "            \\left(\n",
    "                x_i - \\hat{x}_i\n",
    "            \\right)^2 +\n",
    "            \\left(\n",
    "                y_i - \\hat{y}_i\n",
    "            \\right)^2\n",
    "            \\right]\n",
    "\\\\\n",
    "+ \\lambda_\\textbf{coord} \n",
    "\\sum_{i = 0}^{S^2}\n",
    "    \\sum_{j = 0}^{B}\n",
    "         L_{ij}^{\\text{obj}}\n",
    "         \\left[\n",
    "        \\left(\n",
    "            \\sqrt{w_i} - \\sqrt{\\hat{w}_i}\n",
    "        \\right)^2 +\n",
    "        \\left(\n",
    "            \\sqrt{h_i} - \\sqrt{\\hat{h}_i}\n",
    "        \\right)^2\n",
    "        \\right]\n",
    "\\\\\n",
    "+ \\sum_{i = 0}^{S^2}\n",
    "    \\sum_{j = 0}^{B}\n",
    "        L_{ij}^{\\text{obj}}\n",
    "        \\left(\n",
    "            C_i - \\hat{C}_i\n",
    "        \\right)^2\n",
    "\\\\\n",
    "+ \\lambda_\\textrm{noobj}\n",
    "\\sum_{i = 0}^{S^2}\n",
    "    \\sum_{j = 0}^{B}\n",
    "    L_{ij}^{\\text{noobj}}\n",
    "        \\left(\n",
    "            C_i - \\hat{C}_i\n",
    "        \\right)^2\n",
    "\\\\\n",
    "+ \\sum_{i = 0}^{S^2}\n",
    "L_i^{\\text{obj}}\n",
    "    \\sum_{c \\in \\textrm{classes}}\n",
    "        \\left(\n",
    "            p_i(c) - \\hat{p}_i(c)\n",
    "        \\right)^2\n",
    "\\end{multline}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-22T07:04:51.547658Z",
     "start_time": "2017-03-22T15:04:51.470846+08:00"
    },
    "code_folding": [
     0
    ],
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    ### Adjust prediction\n",
    "    # adjust x and y      \n",
    "    pred_box_xy = tf.sigmoid(y_pred[:,:,:,:,:2])\n",
    "    \n",
    "    # adjust w and h\n",
    "    pred_box_wh = tf.exp(y_pred[:,:,:,:,2:4]) * np.reshape(ANCHORS, [1,1,1,BOX,2])\n",
    "    pred_box_wh = tf.sqrt(pred_box_wh / np.reshape([float(GRID_W), float(GRID_H)], [1,1,1,1,2]))\n",
    "    \n",
    "    # adjust confidence\n",
    "    pred_box_conf = tf.expand_dims(tf.sigmoid(y_pred[:, :, :, :, 4]), -1)\n",
    "    \n",
    "    # adjust probability\n",
    "    pred_box_prob = tf.nn.softmax(y_pred[:, :, :, :, 5:])\n",
    "    \n",
    "    y_pred = tf.concat(4, [pred_box_xy, pred_box_wh, pred_box_conf, pred_box_prob])\n",
    "    \n",
    "    ### Adjust ground truth\n",
    "    # adjust x and y\n",
    "    center_xy = .5*(y_true[:,:,:,:,0:2] + y_true[:,:,:,:,2:4])\n",
    "    center_xy = center_xy / np.reshape([(float(NORM_W)/GRID_W), (float(NORM_H)/GRID_H)], [1,1,1,1,2])\n",
    "    true_box_xy = center_xy - tf.floor(center_xy)\n",
    "    \n",
    "    # adjust w and h\n",
    "    true_box_wh = (y_true[:,:,:,:,2:4] - y_true[:,:,:,:,0:2])\n",
    "    true_box_wh = tf.sqrt(true_box_wh / np.reshape([float(NORM_W), float(NORM_H)], [1,1,1,1,2]))\n",
    "    \n",
    "    # adjust confidence\n",
    "    pred_tem_wh = tf.pow(pred_box_wh, 2) * np.reshape([GRID_W, GRID_H], [1,1,1,1,2])\n",
    "    pred_box_area = pred_tem_wh[:,:,:,:,0] * pred_tem_wh[:,:,:,:,1]\n",
    "    pred_box_ul = pred_box_xy - 0.5 * pred_tem_wh\n",
    "    pred_box_bd = pred_box_xy + 0.5 * pred_tem_wh\n",
    "    \n",
    "    true_tem_wh = tf.pow(true_box_wh, 2) * np.reshape([GRID_W, GRID_H], [1,1,1,1,2])\n",
    "    true_box_area = true_tem_wh[:,:,:,:,0] * true_tem_wh[:,:,:,:,1]\n",
    "    true_box_ul = true_box_xy - 0.5 * true_tem_wh\n",
    "    true_box_bd = true_box_xy + 0.5 * true_tem_wh\n",
    "    \n",
    "    intersect_ul = tf.maximum(pred_box_ul, true_box_ul) \n",
    "    intersect_br = tf.minimum(pred_box_bd, true_box_bd)\n",
    "    intersect_wh = intersect_br - intersect_ul\n",
    "    intersect_wh = tf.maximum(intersect_wh, 0.0)\n",
    "    intersect_area = intersect_wh[:,:,:,:,0] * intersect_wh[:,:,:,:,1]\n",
    "    \n",
    "    iou = tf.truediv(intersect_area, true_box_area + pred_box_area - intersect_area)\n",
    "    best_box = tf.equal(iou, tf.reduce_max(iou, [3], True)) \n",
    "    best_box = tf.to_float(best_box)\n",
    "    true_box_conf = tf.expand_dims(best_box * y_true[:,:,:,:,4], -1)\n",
    "    \n",
    "    # adjust confidence\n",
    "    true_box_prob = y_true[:,:,:,:,5:]\n",
    "    \n",
    "    y_true = tf.concat(4, [true_box_xy, true_box_wh, true_box_conf, true_box_prob])\n",
    "    #y_true = tf.Print(y_true, [true_box_wh], message='DEBUGGGGGGGGGG ', summarize=30000)    \n",
    "    \n",
    "    ### Compute the weights\n",
    "    weight_coor = tf.concat(4, 4 * [true_box_conf])\n",
    "    weight_coor = SCALE_COOR * weight_coor\n",
    "    \n",
    "    weight_conf = SCALE_NOOB * (1. - true_box_conf) + SCALE_CONF * true_box_conf\n",
    "    \n",
    "    weight_prob = tf.concat(4, CLASS * [true_box_conf]) \n",
    "    weight_prob = SCALE_PROB * weight_prob \n",
    "    \n",
    "    weight = tf.concat(4, [weight_coor, weight_conf, weight_prob])\n",
    "    \n",
    "    ### Finalize the loss\n",
    "    loss = tf.pow(y_pred - y_true, 2)\n",
    "    loss = loss * weight\n",
    "    loss = tf.reshape(loss, [-1, GRID_W*GRID_H*BOX*(4 + 1 + CLASS)])\n",
    "    loss = tf.reduce_sum(loss, 1)\n",
    "    loss = .5 * tf.reduce_mean(loss)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Randomize weights of the last layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-03-22T15:04:37.310Z"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "layer = model.layers[-3]\n",
    "weights = layer.get_weights()\n",
    "layer.set_weights([np.random.normal(size=weights[0].shape)/(GRID_H*GRID_W), np.random.normal(size=weights[1].shape)/(GRID_H*GRID_W)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Carry out re-training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-03-22T15:04:37.318Z"
    },
    "code_folding": [
     2
    ],
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "Epoch 00000: loss improved from inf to 6.60499, saving model to weights.hdf5\n",
      "757s - loss: 6.6050\n",
      "Epoch 2/500\n",
      "Epoch 00001: loss improved from 6.60499 to 6.09504, saving model to weights.hdf5\n",
      "829s - loss: 6.0950\n",
      "Epoch 3/500\n",
      "Epoch 00002: loss improved from 6.09504 to 5.90255, saving model to weights.hdf5\n",
      "830s - loss: 5.9026\n",
      "Epoch 4/500\n",
      "Epoch 00003: loss improved from 5.90255 to 5.76300, saving model to weights.hdf5\n",
      "829s - loss: 5.7630\n",
      "Epoch 5/500\n",
      "Epoch 00004: loss improved from 5.76300 to 5.68010, saving model to weights.hdf5\n",
      "830s - loss: 5.6801\n",
      "Epoch 6/500\n",
      "Epoch 00005: loss improved from 5.68010 to 5.56108, saving model to weights.hdf5\n",
      "822s - loss: 5.5611\n",
      "Epoch 7/500\n",
      "Epoch 00006: loss improved from 5.56108 to 5.48174, saving model to weights.hdf5\n",
      "822s - loss: 5.4817\n",
      "Epoch 8/500\n",
      "Epoch 00007: loss improved from 5.48174 to 5.41637, saving model to weights.hdf5\n",
      "829s - loss: 5.4164\n",
      "Epoch 9/500\n",
      "Epoch 00008: loss improved from 5.41637 to 5.35519, saving model to weights.hdf5\n",
      "829s - loss: 5.3552\n",
      "Epoch 10/500\n",
      "Epoch 00009: loss improved from 5.35519 to 5.31315, saving model to weights.hdf5\n",
      "829s - loss: 5.3132\n",
      "Epoch 11/500\n",
      "Epoch 00010: loss improved from 5.31315 to 5.23010, saving model to weights.hdf5\n",
      "829s - loss: 5.2301\n",
      "Epoch 12/500\n",
      "Epoch 00011: loss improved from 5.23010 to 5.18669, saving model to weights.hdf5\n",
      "829s - loss: 5.1867\n",
      "Epoch 13/500\n",
      "Epoch 00012: loss improved from 5.18669 to 5.15042, saving model to weights.hdf5\n",
      "829s - loss: 5.1504\n",
      "Epoch 14/500\n",
      "Epoch 00013: loss improved from 5.15042 to 5.09102, saving model to weights.hdf5\n",
      "829s - loss: 5.0910\n",
      "Epoch 15/500\n",
      "Epoch 00014: loss improved from 5.09102 to 5.08733, saving model to weights.hdf5\n",
      "830s - loss: 5.0873\n",
      "Epoch 16/500\n",
      "Epoch 00015: loss improved from 5.08733 to 5.02548, saving model to weights.hdf5\n",
      "830s - loss: 5.0255\n",
      "Epoch 17/500\n",
      "Epoch 00016: loss improved from 5.02548 to 4.99885, saving model to weights.hdf5\n",
      "830s - loss: 4.9988\n",
      "Epoch 18/500\n",
      "Epoch 00017: loss improved from 4.99885 to 4.95003, saving model to weights.hdf5\n",
      "825s - loss: 4.9500\n",
      "Epoch 19/500\n",
      "Epoch 00018: loss improved from 4.95003 to 4.91029, saving model to weights.hdf5\n",
      "830s - loss: 4.9103\n",
      "Epoch 20/500\n",
      "Epoch 00019: loss improved from 4.91029 to 4.86424, saving model to weights.hdf5\n",
      "830s - loss: 4.8642\n",
      "Epoch 21/500\n",
      "Epoch 00020: loss improved from 4.86424 to 4.83960, saving model to weights.hdf5\n",
      "830s - loss: 4.8396\n",
      "Epoch 22/500\n",
      "Epoch 00021: loss improved from 4.83960 to 4.80028, saving model to weights.hdf5\n",
      "830s - loss: 4.8003\n",
      "Epoch 23/500\n",
      "Epoch 00022: loss improved from 4.80028 to 4.77685, saving model to weights.hdf5\n",
      "824s - loss: 4.7769\n",
      "Epoch 24/500\n",
      "Epoch 00023: loss improved from 4.77685 to 4.72854, saving model to weights.hdf5\n",
      "826s - loss: 4.7285\n",
      "Epoch 25/500\n",
      "Epoch 00024: loss improved from 4.72854 to 4.68884, saving model to weights.hdf5\n",
      "830s - loss: 4.6888\n",
      "Epoch 26/500\n",
      "Epoch 00025: loss improved from 4.68884 to 4.68524, saving model to weights.hdf5\n",
      "824s - loss: 4.6852\n",
      "Epoch 27/500\n",
      "Epoch 00026: loss improved from 4.68524 to 4.65091, saving model to weights.hdf5\n",
      "821s - loss: 4.6509\n",
      "Epoch 28/500\n",
      "Epoch 00027: loss improved from 4.65091 to 4.60274, saving model to weights.hdf5\n",
      "825s - loss: 4.6027\n",
      "Epoch 29/500\n",
      "Epoch 00028: loss improved from 4.60274 to 4.56757, saving model to weights.hdf5\n",
      "826s - loss: 4.5676\n",
      "Epoch 30/500\n",
      "Epoch 00029: loss improved from 4.56757 to 4.54430, saving model to weights.hdf5\n",
      "825s - loss: 4.5443\n",
      "Epoch 31/500\n",
      "Epoch 00030: loss improved from 4.54430 to 4.53296, saving model to weights.hdf5\n",
      "824s - loss: 4.5330\n",
      "Epoch 32/500\n",
      "Epoch 00031: loss improved from 4.53296 to 4.48304, saving model to weights.hdf5\n",
      "831s - loss: 4.4830\n",
      "Epoch 33/500\n",
      "Epoch 00032: loss improved from 4.48304 to 4.45481, saving model to weights.hdf5\n",
      "830s - loss: 4.4548\n",
      "Epoch 34/500\n",
      "Epoch 00033: loss improved from 4.45481 to 4.43549, saving model to weights.hdf5\n",
      "830s - loss: 4.4355\n",
      "Epoch 35/500\n",
      "Epoch 00034: loss improved from 4.43549 to 4.38622, saving model to weights.hdf5\n",
      "830s - loss: 4.3862\n",
      "Epoch 36/500\n"
     ]
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='loss', min_delta=0.01, patience=5, mode='min', verbose=1)\n",
    "checkpoint = ModelCheckpoint('weights.hdf5', monitor='loss', verbose=1, save_best_only=True, mode='min', period=1)\n",
    "\n",
    "model.compile(loss=custom_loss, optimizer='adagrad')\n",
    "model.fit_generator(data_gen(all_img, BATCH_SIZE), len(all_img), 500, verbose=2, callbacks=[early_stop, checkpoint], max_q_size=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Perform detection on image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-03-22T15:04:37.323Z"
    },
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"weights.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-03-22T15:04:37.329Z"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('horses.jpg')\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "input_image = cv2.resize(image, (416, 416))\n",
    "input_image = input_image / 255.\n",
    "input_image = input_image[:,:,::-1]\n",
    "input_image = np.expand_dims(input_image, 0)\n",
    "\n",
    "netout = model.predict(input_image)\n",
    "\n",
    "#print netout\n",
    "image = interp_netout(image, netout[0])\n",
    "plt.imshow(image[:,:,::-1]); plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "381px",
    "width": "251px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "589px",
    "left": "0px",
    "right": "1096px",
    "top": "32px",
    "width": "253px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
